<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>threat-modeling on xvnpw personal blog</title><link>https://xvnpw.github.io/tags/threat-modeling/</link><description>Recent content in threat-modeling on xvnpw personal blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 03 Sep 2023 08:59:02 +0100</lastBuildDate><atom:link href="https://xvnpw.github.io/tags/threat-modeling/index.xml" rel="self" type="application/rss+xml"/><item><title>Leveraging LLMs for Threat Modeling - GPT-3.5 vs Claude 2 vs GPT-4</title><link>https://xvnpw.github.io/posts/leveraging-llms-for-threat-modelling-gpt-3.5-vs-claude2-vs-gpt-4/</link><pubDate>Sun, 03 Sep 2023 08:59:02 +0100</pubDate><guid>https://xvnpw.github.io/posts/leveraging-llms-for-threat-modelling-gpt-3.5-vs-claude2-vs-gpt-4/</guid><description>I tested the most important LLMs (GPT-3.5, Claude 2, and GPT-4) for ability to perform threat modeling. Let&amp;rsquo;s check results and find out which performed best.
This quote from Ethan Mollick, who is professor at The Wharton School, resonates very much with my experience on LLMs. Answers from GPT look like someone tried to satisfy question in the easiest way possible üòè You can overcome that by asking for explanation or step-by-step thinking.</description></item><item><title>Leveraging LLMs for Threat Modeling - GPT-3.5</title><link>https://xvnpw.github.io/posts/leveraging-llms-for-threat-modelling-gpt-3.5/</link><pubDate>Thu, 17 Aug 2023 18:59:02 +0100</pubDate><guid>https://xvnpw.github.io/posts/leveraging-llms-for-threat-modelling-gpt-3.5/</guid><description>In this article, I delve into the AI Nutrition-Pro experiment, a research project exploring the potential of LLMs in enhancing security practices during the design phase of DevSecOps: threat modeling and security review.
DevSecOps: A Brief Overview DevSecOps merges the principles of development, security, and operations to create a culture of shared responsibility for software security. The three main goals of DevSecOps are:
Shift Left Security: Identifying and addressing security vulnerabilities as early as possible in the software development lifecycle.</description></item><item><title>Threat Modeling 101</title><link>https://xvnpw.github.io/posts/threat_modeling_101/</link><pubDate>Wed, 19 Oct 2022 18:59:02 +0100</pubDate><guid>https://xvnpw.github.io/posts/threat_modeling_101/</guid><description>What is Threat Modeling? First of all, it&amp;rsquo;s just thinking about threats. We all do it, every day üòÉ &amp;ldquo;How someone could break into my house?&amp;rdquo; But wait a second. How do you know that you need to protect your house in the first place? Maybe you don&amp;rsquo;t have a house, or maybe you don&amp;rsquo;t have money right now to buy deterrents. Or maybe your family thinks you are a bit paranoid?</description></item></channel></rss>