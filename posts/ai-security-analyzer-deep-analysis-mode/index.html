<!doctype html><html><head lang=en><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Deep Analysis Mode in AI Security Analyzer - xvnpw personal blog</title><link rel=icon type=image/png href=/favicon.png><meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="Discover how the new Deep Analysis Mode in AI Security Analyzer provides in-depth security insights, with practical examples using Google's Gemini 2.0 Flash Thinking Experimental model."><meta property="og:image" content><meta property="og:url" content="https://xvnpw.github.io/posts/ai-security-analyzer-deep-analysis-mode/"><meta property="og:site_name" content="xvnpw personal blog"><meta property="og:title" content="Deep Analysis Mode in AI Security Analyzer"><meta property="og:description" content="Discover how the new Deep Analysis Mode in AI Security Analyzer provides in-depth security insights, with practical examples using Google's Gemini 2.0 Flash Thinking Experimental model."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-01-10T20:00:00+01:00"><meta property="article:modified_time" content="2025-01-10T20:00:00+01:00"><meta property="article:tag" content="Security"><meta property="article:tag" content="Ai"><meta property="article:tag" content="Gemini"><meta property="article:tag" content="Threat-Modeling"><meta property="article:tag" content="Flask"><meta property="article:tag" content="Github"><meta name=twitter:card content="summary"><meta name=twitter:title content="Deep Analysis Mode in AI Security Analyzer"><meta name=twitter:description content="Discover how the new Deep Analysis Mode in AI Security Analyzer provides in-depth security insights, with practical examples using Google's Gemini 2.0 Flash Thinking Experimental model."><link href=https://xvnpw.github.io/css/fonts.2c2227b81b1970a03e760aa2e6121cd01f87c88586803cbb282aa224720a765f.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://xvnpw.github.io/css/main.6a0f23ea50fd34b46fee262a5a68e17d458c51a2bc99ba1ba018065de6b180c3.css><link id=darkModeStyle rel=stylesheet type=text/css href=https://xvnpw.github.io/css/dark.50b57e12d401420df23965fed157368aba37b76df0ecefd0b1ecd4da664f01a0.css media="(prefers-color-scheme: dark)"><link rel=stylesheet type=text/css href=https://xvnpw.github.io/css/my.6e08ae20ebbcf10b8953bc0c3935a825ae172c99096f9af1bf2df91a6d21a1be.css></head><body><div class=content><header><div class=main><a href=https://xvnpw.github.io/>xvnpw personal blog</a></div><nav><a href=/>Home</a>
<a href=/posts>All posts</a>
<a href=/about>About</a>
<a href=/tags>Tags</a></nav></header><main><article><div class=post-container><div class=post-content><div class=title><h1 class=title>Deep Analysis Mode in AI Security Analyzer</h1><div class=meta>Posted on Jan 10, 2025</div></div><section class=body><p>First off, <strong>a big thank you</strong> üôá to everyone who provided such positive feedback on my previous post, <a href=https://xvnpw.github.io/posts/scaling-threat-modeling-with-ai/>Scaling Threat Modeling with AI: Generating 1000 Threat Models Using Gemini 2.0 and AI Security Analyzer</a>. Your insights and suggestions have been incredibly valuable.</p><p>Inspired by your comments, I&rsquo;ve added a new feature to the AI Security Analyzer: <strong>Deep Analysis Mode</strong>. In this post, I&rsquo;ll walk you through how it works and showcase its capabilities using Google&rsquo;s Gemini 2.0 Flash Thinking Experimental model to perform an in-depth threat modeling on the <a href=https://github.com/pallets/flask>Flask</a> project. We&rsquo;ll compare outputs between Normal Mode and Deep Analysis Mode to highlight the differences.</p><h2 id=motivation>Motivation</h2><p>Some of you asked for more detailed analyses of projects in the <code>sec-docs</code> repository. I wasn&rsquo;t sure if Gemini 2.0 could provide deeper insights, so I decided to try it out. With Google planning to remove free access to Gemini 2.0 Flash soon, I rushed to implement this feature. The final results aren&rsquo;t perfect, but I believe they can be quite useful in many cases.</p><h2 id=activating-deep-analysis>Activating Deep Analysis</h2><p>Enabling deep analysis is straightforward. You simply add the <code>--deep-analysis</code> flag when running the tool in <strong>github</strong> mode:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>poetry run python ai_security_analyzer/app.py <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    github <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    -t https://github.com/user/repo <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    -o output.md <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --agent-prompt-type threat-modeling <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --deep-analysis
</span></span></code></pre></div><h2 id=the-multi-document-approach>The Multi-Document Approach</h2><p>What makes deep analysis different from normal mode is its multi-document output strategy. Depending on what you&rsquo;re analyzing, the tool generates different sets of documentation:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-markdown data-lang=markdown><span style=display:flex><span>Output Structure:
</span></span><span style=display:flex><span>üìÑ Main Document (output.md)
</span></span><span style=display:flex><span>‚îî‚îÄ‚îÄ Detailed Analysis Files:
</span></span><span style=display:flex><span>    ‚îú‚îÄ‚îÄ üéØ threats/*.md            # For threat modeling
</span></span><span style=display:flex><span>    ‚îú‚îÄ‚îÄ üîç attack_surfaces/*.md    # For attack surface analysis
</span></span><span style=display:flex><span>    ‚îú‚îÄ‚îÄ üå≥ attack_tree_paths/*.md  # For attack tree analysis
</span></span><span style=display:flex><span>    ‚îî‚îÄ‚îÄ üîí output-deep-analysis.md # For security design
</span></span></code></pre></div><p>This structured approach means you get both a high-level overview and detailed deep dives into specific aspects of your security analysis.</p><h2 id=a-word-of-caution>A Word of Caution</h2><p>While Deep Analysis Mode provides richer insights, it&rsquo;s essential to be mindful of a few points:</p><ul><li><strong>Currently limited to <code>github</code> mode</strong></li><li><strong>Outputs require careful verification</strong></li><li><strong>Potential for AI hallucinations</strong></li><li><strong>Cost Implications</strong>: Currently, using Gemini 2.0 Flash is free (as of January, 2025), but this might change. Deep Analysis Mode doesn&rsquo;t support the <code>--dry-run</code> flag, so you can&rsquo;t get an estimated cost upfront. However, you can refer to the <a href=https://github.com/xvnpw/sec-docs/blob/0fb6183ff9d58e719685fd498efeffdea370fe98/go/cilium/cilium/2025-01-05-gemini-2.0-flash-thinking-exp/output-metadata.json>output-metadata.json</a> from previous executions to gauge potential costs. For instance, analyzing Flask cost around 180,000 tokens (<code>"actual_token_usage": "175994"</code>).</li></ul><h2 id=comparing-normal-vs-deep-analysis>Comparing Normal vs Deep Analysis</h2><p>Normal Mode provides an overview with easily digestible documents, serving as a starting point for further analysis or as a checklist for potential issues. Deep Analysis Mode, on the other hand, offers a much more detailed examination. However, depending on the model used, the outputs might:</p><ul><li>Contain deeper, specific analyses (<strong>preferred</strong>)</li><li>Include more general, common threats (<strong>less preferred</strong>)</li><li>Contain verbose text without added value (<strong>less preferred</strong>)</li></ul><p>It&rsquo;s important to note that Deep Analysis Mode starts with the same initial steps as Normal Mode. We need a high-level overview of the project before we can delve deeper.</p><h2 id=prompts>Prompts</h2><p>Prompts are very simple. For example, for threat modeling, we use the following prompt:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>GITHUB2_GET_THREAT_DETAILS_PROMPT = &#34;&#34;&#34;You are cybersecurity expert, working with development team. Your task is to create deep analysis of particular threat from threat model for application that is using {}.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>THREAT:
</span></span><span style=display:flex><span>{}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>{}
</span></span><span style=display:flex><span>&#34;&#34;&#34;
</span></span></code></pre></div><p>For <code>{}</code> I will provide:</p><ol><li>GitHub repository URL, e.g. <a href=https://github.com/pallets/flask>https://github.com/pallets/flask</a></li><li>Threat title from threat model</li><li>Threat description from threat model</li></ol><p>You can check other prompts for deep analysis in the <a href=https://github.com/xvnpw/ai-security-analyzer/blob/337cd9aa56e9ae66017f04fe3fdbb3c2f855a21e/ai_security_analyzer/prompts.py#L844C1-L850C4>prompts.py</a> file and see how they are used in <a href=https://github.com/xvnpw/ai-security-analyzer/blob/337cd9aa56e9ae66017f04fe3fdbb3c2f855a21e/ai_security_analyzer/github2tm_agents.py#L165>github2tm_agents.py</a>.</p><h2 id=deep-analysis-of-flask-framework>Deep Analysis of Flask framework</h2><p>To illustrate the capabilities of Deep Analysis Mode, let&rsquo;s compare the outputs of Normal Mode and Deep Analysis Mode for the Flask framework, focusing specifically on the threat modeling documents.</p><h3 id=threats-identified-in-normal-mode>Threats Identified in Normal Mode</h3><p>In the previous post, the Normal Mode analysis of Flask identified the following <strong>five threats</strong> (<a href=https://github.com/xvnpw/ai-security-analyzer/blob/main/examples/GITHUB-THREAT-MODEL-FLASK-gemini-2.0-flash-thinking-exp.md>github</a>):</p><ol><li><strong>Route Parameter Injection</strong></li><li><strong>Insecure Session Cookie Configuration</strong></li><li><strong>Debug Mode Enabled in Production</strong></li><li><strong>Blueprint Route Conflicts and Overlapping</strong></li><li><strong>Incorrect HTTP Method Handling</strong></li></ol><h3 id=threats-identified-in-deep-analysis-mode>Threats Identified in Deep Analysis Mode</h3><p>After enabling Deep Analysis Mode, the analysis resulted in <strong>four threats</strong> (<a href=https://github.com/xvnpw/sec-docs/blob/main/python/pallets/flask/2025-01-03-gemini-2.0-flash-thinking-exp/threat-modeling.md>github</a>):</p><ol><li><strong>Server-Side Template Injection (SSTI)</strong></li><li><strong>Insecure Secret Key Management</strong></li><li><strong>Exposure of Debug Mode in Production</strong></li><li><strong>Session Fixation</strong></li></ol><p>ü§î <strong>Note</strong>: The variance in the number of threats is due to the inherent randomness in LLM outputs, influenced by the temperature setting (set at 0.5 in this case).</p><h3 id=common-threat-debug-mode-enabled-in-production>Common Threat: Debug Mode Enabled in Production</h3><p>Both modes identified the threat related to <strong>Debug Mode in Production</strong>. Let&rsquo;s examine how each mode handles this threat.</p><h4 id=normal-mode-output>Normal Mode Output</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-markdown data-lang=markdown><span style=display:flex><span><span style=color:#66d9ef>*</span>   <span style=font-weight:700>**Threat:**</span> Debug Mode Enabled in Production
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>*</span>   <span style=font-weight:700>**Description:**</span> Running a Flask application with <span style=color:#e6db74>`debug=True`</span> configures the <span style=color:#e6db74>`flask.Flask`</span> application to expose an interactive debugger in the browser when an error occurs. Attackers can exploit this debugger to execute arbitrary code on the server, access sensitive information, and potentially gain full control of the application.
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>*</span>   <span style=font-weight:700>**Impact:**</span> Complete server compromise, data breaches, denial of service.
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>*</span>   <span style=font-weight:700>**Affected Flask Component:**</span> <span style=color:#e6db74>`flask.Flask`</span>, <span style=color:#e6db74>`debug`</span> configuration parameter.
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>*</span>   <span style=font-weight:700>**Risk Severity:**</span> Critical
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>*</span>   <span style=font-weight:700>**Mitigation Strategies:**</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>*</span>   <span style=font-weight:700>**Never**</span> run Flask applications with <span style=color:#e6db74>`debug=True`</span> in production environments. Ensure <span style=color:#e6db74>`app.debug = False`</span> or the <span style=color:#e6db74>`FLASK_DEBUG=0`</span> environment variable is set.
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>*</span>   Implement proper logging and error reporting mechanisms for production.
</span></span></code></pre></div><p>This output provides a concise and actionable summary of the threat, its impact, and mitigation strategies.</p><h4 id=deep-analysis-mode-output>Deep Analysis Mode Output</h4><p>In Deep Analysis Mode, the threat is explored in much greater depth. The analysis includes:</p><ol><li><strong>Understanding the Threat in Detail</strong></li><li><strong>Attack Vectors and Exploitation Scenarios</strong></li><li><strong>Detailed Impact Analysis</strong></li><li><strong>Prevention Strategies (Elaborated)</strong></li><li><strong>Detection Strategies</strong></li><li><strong>Remediation Steps (If Debug Mode is Found Enabled)</strong></li><li><strong>Communication and Collaboration</strong></li><li><strong>Conclusion</strong></li></ol><p><strong>Example Excerpt from Deep Analysis Mode:</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-markdown data-lang=markdown><span style=display:flex><span>**1. Understanding the Threat in Detail:**
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>While the initial description provides a good overview, let&#39;s delve deeper into the mechanics and implications of running a Flask application with debug mode enabled in a production environment.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>*</span> **The Nature of Flask&#39;s Debug Mode:**
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>*</span> **Automatic Code Reloading:** Any changes to the application&#39;s Python code will automatically restart the server. While useful during development, this can lead to unexpected downtime and instability in production if files are inadvertently modified or if the reloading process encounters errors.
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>*</span> **Interactive Debugger Exposure:** The Werkzeug debugger allows for code execution within the browser. If exposed, an attacker can execute arbitrary code on the server.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>**2. Attack Vectors and Exploitation Scenarios:**</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>How could an attacker exploit this vulnerability?
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>*</span> **Direct Access to Error Pages:**
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>*</span> **Submitting Invalid Input:** Crafting malicious requests designed to cause exceptions.
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>*</span> **Exploiting Existing Vulnerabilities:** Leveraging other vulnerabilities that lead to errors.
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>*</span> **Accessing Non-Existent Routes:** Triggering 404 errors that reveal application structure.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>**3. Detailed Impact Analysis:**</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>*</span> **Information Disclosure (Critical):**
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>*</span> Exposure of source code, configuration details, and local variables.
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>*</span> Attackers gain significant insights into the application&#39;s security mechanisms.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>**4. Prevention Strategies (Elaborated):**</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>*</span> **Explicitly Disable Debug Mode in Production:**
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>*</span> **Environment Variables (<span style=color:#e6db74>`FLASK_DEBUG`</span>):** Set <span style=color:#e6db74>`FLASK_DEBUG=0`</span> or <span style=color:#e6db74>`False`</span> in production environments.
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>*</span> **Application Configuration (<span style=color:#e6db74>`app.debug`</span>):** Ensure <span style=color:#e6db74>`app.debug = False`</span>.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>**5. Detection Strategies:**</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>*</span> **Manual Inspection:** Check environment variables and application configuration.
</span></span><span style=display:flex><span><span style=color:#66d9ef>*</span> **Automated Checks:** Implement scripts or CI/CD pipeline checks to ensure <span style=color:#e6db74>`FLASK_DEBUG`</span> is disabled.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>**6. Remediation Steps (If Debug Mode is Found Enabled):**</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>1.</span> <span style=font-weight:700>**Immediately Disable Debug Mode.**</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>2.</span> <span style=font-weight:700>**Investigate for Potential Compromise:**</span> Review logs and monitor alerts.
</span></span><span style=display:flex><span><span style=color:#66d9ef>3.</span> <span style=font-weight:700>**Assess and Update Security Policies.**</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>**7. Communication and Collaboration:**</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>*</span> **Clear Communication:** Ensure all team members understand the risks.
</span></span><span style=display:flex><span><span style=color:#66d9ef>*</span> **Training:** Provide security awareness training.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>**Conclusion:**</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Running Flask&#39;s debug mode in production poses a severe security risk. Immediate steps should be taken to disable it and secure the application.
</span></span></code></pre></div><h4 id=analysis-of-the-outputs>Analysis of the Outputs</h4><p>While the Deep Analysis Mode provides a more exhaustive examination, including attack vectors, detailed impacts, and remediation steps, it&rsquo;s worth considering:</p><ul><li><strong>Value Addition</strong>: The extra details can be beneficial for deeper understanding and planning comprehensive security measures.</li><li><strong>Relevance</strong>: Some sections may contain generalized information that doesn&rsquo;t add significant value to seasoned professionals.</li><li><strong>Time Investment</strong>: Reviewing longer documents requires more time and may include redundant information.</li></ul><h2 id=lessons-learned>Lessons Learned</h2><p>Key Takeaways:</p><ul><li>Choose between modes based on your specific needs</li><li>Consider the trade-offs between depth and efficiency</li><li>Always verify AI-generated outputs</li></ul><h2 id=sec-docs-repository><code>sec-docs</code> Repository</h2><p>I generated a new set of documentation for 1,000 projects in my <a href=https://github.com/xvnpw/sec-docs>sec-docs</a> repository. You can find it by browsing the language-specific folders or by looking at specific projects:</p><figure class=image-center><img src=https://github.com/user-attachments/assets/3c85e401-c11e-4034-bfff-b97306748e63></figure><h2 id=looking-forward>Looking Forward</h2><p>I plan to continue refining the tool and explore how other models, especially those from OpenAI, perform in Deep Analysis Mode.</p><h2 id=want-to-try-it-yourself>Want to Try It Yourself?</h2><p>The AI Security Analyzer tool is available on <a href=https://github.com/xvnpw/ai-security-analyzer>GitHub</a>, and I encourage you to experiment with both modes. Your feedback is highly appreciated.</p><hr><p>Thanks for reading! You can contact me and/or follow me on <a href=https://x.com/xvnpw>X</a> and <a href=https://linkedin.com/in/marcin-niemiec-304349104>LinkedIn</a>.</p></section><div class=post-tags><nav class="nav tags"><ul class=tags><li><a href=/tags/security>security</a></li><li><a href=/tags/ai>ai</a></li><li><a href=/tags/gemini>gemini</a></li><li><a href=/tags/threat-modeling>threat modeling</a></li><li><a href=/tags/flask>flask</a></li><li><a href=/tags/github>github</a></li><li><a href=/tags/llm>llm</a></li></ul></nav></div></div></div></article></main><footer><div style=display:flex><a class=soc href=https://github.com/xvnpw rel=me title=GitHub><svg class="feather"><use href="/svg/feather-sprite.51cf5647cb1987f769b616558f2620fd9423d72058490231b391bf6aa3744b55.svg#github"/></svg></a><a class=border></a><a class=soc href=https://twitter.com/xvnpw rel=me title=Twitter><svg class="feather"><use href="/svg/feather-sprite.51cf5647cb1987f769b616558f2620fd9423d72058490231b391bf6aa3744b55.svg#twitter"/></svg></a><a class=border></a><a class=soc href=https://www.linkedin.com/in/marcin-niemiec-304349104/ rel=me title=Linkedin><svg class="feather"><use href="/svg/feather-sprite.51cf5647cb1987f769b616558f2620fd9423d72058490231b391bf6aa3744b55.svg#linkedin"/></svg></a><a class=border></a></div><div class=footer-info>2025 <a href=https://github.com/athul/archie>Archie Theme</a> | Built with <a href=https://gohugo.io>Hugo</a></div></footer><script async src="https://www.googletagmanager.com/gtag/js?id=G-YHETMXZXMZ"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-YHETMXZXMZ")}</script></div></body></html>