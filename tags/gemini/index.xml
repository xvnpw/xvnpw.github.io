<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Gemini on xvnpw personal blog</title><link>https://xvnpw.github.io/tags/gemini/</link><description>Recent content in Gemini on xvnpw personal blog</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Fri, 10 Jan 2025 20:00:00 +0100</lastBuildDate><atom:link href="https://xvnpw.github.io/tags/gemini/index.xml" rel="self" type="application/rss+xml"/><item><title>Deep Analysis Mode in AI Security Analyzer</title><link>https://xvnpw.github.io/posts/ai-security-analyzer-deep-analysis-mode/</link><pubDate>Fri, 10 Jan 2025 20:00:00 +0100</pubDate><guid>https://xvnpw.github.io/posts/ai-security-analyzer-deep-analysis-mode/</guid><description>&lt;p>First off, &lt;strong>a big thank you&lt;/strong> ðŸ™‡ to everyone who provided such positive feedback on my previous post, &lt;a href="https://xvnpw.github.io/posts/scaling-threat-modeling-with-ai/">Scaling Threat Modeling with AI: Generating 1000 Threat Models Using Gemini 2.0 and AI Security Analyzer&lt;/a>. Your insights and suggestions have been incredibly valuable.&lt;/p>
&lt;p>Inspired by your comments, I&amp;rsquo;ve added a new feature to the AI Security Analyzer: &lt;strong>Deep Analysis Mode&lt;/strong>. In this post, I&amp;rsquo;ll walk you through how it works and showcase its capabilities using Google&amp;rsquo;s Gemini 2.0 Flash Thinking Experimental model to perform an in-depth threat modeling on the &lt;a href="https://github.com/pallets/flask">Flask&lt;/a> project. We&amp;rsquo;ll compare outputs between Normal Mode and Deep Analysis Mode to highlight the differences.&lt;/p></description></item><item><title>Scaling Threat Modeling with AI: Generating 1000 Threat Models Using Gemini 2.0 and AI Security Analyzer</title><link>https://xvnpw.github.io/posts/scaling-threat-modeling-with-ai/</link><pubDate>Wed, 01 Jan 2025 12:19:02 +0100</pubDate><guid>https://xvnpw.github.io/posts/scaling-threat-modeling-with-ai/</guid><description>&lt;p>&amp;ldquo;Can AI help us scale security analysis?&amp;rdquo; This question led me down a fascinating path of experimenting with Google&amp;rsquo;s Gemini 2.0 to generate threat models at an unprecedented scale. In this post, I&amp;rsquo;ll share how I turned this ambitious idea into reality, complete with code samples, real outputs, and valuable lessons learned along the way.&lt;/p>
&lt;h2 id="the-challenge-automating-security-analysis-at-scale">The Challenge: Automating Security Analysis at Scale&lt;/h2>
&lt;p>Security documentation is crucial but often becomes a bottleneck in fast-moving development cycles. With the release of Google&amp;rsquo;s Gemini 2.0 Flash Thinking Experimental model, I saw an opportunity to tackle this challenge head-on, despite some notable limitations:&lt;/p></description></item></channel></rss>