<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Claude on xvnpw personal blog</title><link>https://xvnpw.github.io/tags/claude/</link><description>Recent content in Claude on xvnpw personal blog</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Mon, 03 Jun 2024 16:59:02 +0100</lastBuildDate><atom:link href="https://xvnpw.github.io/tags/claude/index.xml" rel="self" type="application/rss+xml"/><item><title>Threat Modelling with Fabric Framework</title><link>https://xvnpw.github.io/posts/threat_modelling_with_fabric_framework/</link><pubDate>Mon, 03 Jun 2024 16:59:02 +0100</pubDate><guid>https://xvnpw.github.io/posts/threat_modelling_with_fabric_framework/</guid><description>Fabric is a framework that puts AI at your fingertips. Instead of diving into chat interfaces (e.g., ChatGPT) or writing custom programs that consume APIs, you can create prompts as markdown text and receive output in markdown. Fabric also maintains a database of prompts called patterns.
With the new pattern create_stride_threat_model, you can easily create threat models. Let&amp;rsquo;s dive deeper into how to use this new pattern and evaluate the quality of the results.</description></item><item><title>Leveraging LLMs for Threat Modeling - Claude 3 Opus vs GPT-4</title><link>https://xvnpw.github.io/posts/leveraging-llms-for-threat-modelling-claude-3-vs-gpt-4/</link><pubDate>Wed, 20 Mar 2024 14:59:02 +0100</pubDate><guid>https://xvnpw.github.io/posts/leveraging-llms-for-threat-modelling-claude-3-vs-gpt-4/</guid><description>Claude 3 Opus is the latest and most powerful model from Anthropic. Is it able to overcome GPT-4?
Revisiting the Experiment If you wish to understand more about the experiment structure, you can refer to my previous post. But here&amp;rsquo;s a quick recap:
I used markdown files describing a fictional project, AI Nutrition-Pro, with input:
PROJECT.md - high level project description ARCHITECTURE.md - architecture description 0001_STORE_DIET_INTRODUCTIONS.md - user story I tasked the AI models with four types of analysis: high-level security design review, threat modeling, security-related acceptance criteria and review of architecture:</description></item><item><title>Leveraging LLMs for Threat Modeling - GPT-3.5 vs Claude 2 vs GPT-4</title><link>https://xvnpw.github.io/posts/leveraging-llms-for-threat-modelling-gpt-3.5-vs-claude2-vs-gpt-4/</link><pubDate>Sun, 03 Sep 2023 08:59:02 +0100</pubDate><guid>https://xvnpw.github.io/posts/leveraging-llms-for-threat-modelling-gpt-3.5-vs-claude2-vs-gpt-4/</guid><description>In a bid to uncover which AI model is best at threat modeling, I put GPT-3.5, Claude 2, and GPT-4 to the test. Let&amp;rsquo;s see how they performed.
Ethan Mollick, a professor at The Wharton School, once said something that perfectly captures my experience with these AI models. It feels as if they&amp;rsquo;re striving to answer questions in the simplest way possible üòè However, you can get around this by asking for detailed explanations or step-by-step thinking.</description></item></channel></rss>