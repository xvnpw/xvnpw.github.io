<!doctype html><html><head lang=en><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>xvnpw personal blog | Home </title><link rel=icon type=image/png href=/favicon.png><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content><meta property="og:image" content><link rel=alternate type=application/rss+xml href=https://xvnpw.github.io/index.xml title="xvnpw personal blog"><meta property="og:url" content="https://xvnpw.github.io/"><meta property="og:site_name" content="xvnpw personal blog"><meta property="og:title" content="xvnpw personal blog"><meta property="og:locale" content="en_us"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="xvnpw personal blog"><link href=https://xvnpw.github.io/css/fonts.2c2227b81b1970a03e760aa2e6121cd01f87c88586803cbb282aa224720a765f.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://xvnpw.github.io/css/main.6a0f23ea50fd34b46fee262a5a68e17d458c51a2bc99ba1ba018065de6b180c3.css><link id=darkModeStyle rel=stylesheet type=text/css href=https://xvnpw.github.io/css/dark.50b57e12d401420df23965fed157368aba37b76df0ecefd0b1ecd4da664f01a0.css media="(prefers-color-scheme: dark)"><link rel=stylesheet type=text/css href=https://xvnpw.github.io/css/my.6e08ae20ebbcf10b8953bc0c3935a825ae172c99096f9af1bf2df91a6d21a1be.css></head><body><div class=content><header><div class=main><a href=https://xvnpw.github.io/>xvnpw personal blog</a></div><nav><a href=/>Home</a>
<a href=/posts>All posts</a>
<a href=/about>About</a>
<a href=/tags>Tags</a></nav></header><main class=list><div class=site-description><p>hacking, bug bounty, appsec</p></div><section class=list-item><h1 class=title><a href=/posts/can-ai-actually-find-real-security-bugs-testing-the-new-wave-of-ai-models/>Can AI Actually Find Real Security Bugs? Testing the New Wave of AI Models</a></h1><time>Feb 14, 2025</time><br><div class=description>A practical exploration of how well reasoning LLMs identify vulnerabilities in real-world code, comparing results across models and against a traditional SAST tool (Semgrep).</div><a class=readmore href=/posts/can-ai-actually-find-real-security-bugs-testing-the-new-wave-of-ai-models/>Read more ⟶</a></section><section class=list-item><h1 class=title><a href=/posts/forget-threats-mitigations-are-all-you-really-need/>Forget Threats, Mitigations are All You REALLY Need</a></h1><time>Feb 2, 2025</time><br><div class=description>A practical perspective shift for security professionals: Learn why focusing on concrete mitigations rather than abstract threats leads to better developer engagement and more secure software. Featuring hands-on examples using AI-powered security analysis tools and real-world project implementations.</div><a class=readmore href=/posts/forget-threats-mitigations-are-all-you-really-need/>Read more ⟶</a></section><section class=list-item><h1 class=title><a href=/posts/ai-security-analyzer-deep-analysis-mode/>Deep Analysis Mode in AI Security Analyzer</a></h1><time>Jan 10, 2025</time><br><div class=description>Discover how the new Deep Analysis Mode in AI Security Analyzer provides in-depth security insights, with practical examples using Google's Gemini 2.0 Flash Thinking Experimental model.</div><a class=readmore href=/posts/ai-security-analyzer-deep-analysis-mode/>Read more ⟶</a></section><section class=list-item><h1 class=title><a href=/posts/scaling-threat-modeling-with-ai/>Scaling Threat Modeling with AI: Generating 1000 Threat Models Using Gemini 2.0 and AI Security Analyzer</a></h1><time>Jan 1, 2025</time><br><div class=description>An in-depth look at how I leveraged Gemini 2.0 to create a massive security documentation repository, complete with practical examples and lessons learned.</div><a class=readmore href=/posts/scaling-threat-modeling-with-ai/>Read more ⟶</a></section><section class=list-item><h1 class=title><a href=/posts/ai-security-analyzer-all-in-one-tool-preview/>AI Security Analyzer - All-in-One Tool Preview</a></h1><time>Dec 19, 2024</time><br><div class=description>Preview of the AI Security Analyzer - a new tool that leverages AI to automatically generate comprehensive security design documentation for your projects.</div><a class=readmore href=/posts/ai-security-analyzer-all-in-one-tool-preview/>Read more ⟶</a></section><section class=list-item><h1 class=title><a href=/posts/automating-github-workflows-with-fabric-agent-action/>Automating GitHub Workflows with Fabric Agent Action</a></h1><time>Nov 22, 2024</time><br><div class=description>Introducing the Fabric Agent Action - a GitHub Action that automates complex workflows using AI-powered agents and Fabric Patterns.</div><a class=readmore href=/posts/automating-github-workflows-with-fabric-agent-action/>Read more ⟶</a></section><section class=list-item><h1 class=title><a href=/posts/fabric_design_documents/>Create design documents with Fabric</a></h1><time>Oct 30, 2024</time><br><div class=description>How I use Fabric patterns to create, review and refine design documents.</div><a class=readmore href=/posts/fabric_design_documents/>Read more ⟶</a></section><section class=list-item><h1 class=title><a href=/posts/threat_modelling_with_fabric_framework/>Threat Modelling with Fabric Framework</a></h1><time>Jun 3, 2024</time><br><div class=description>The Fabric framework enhances AI-powered threat modeling with a new pattern, offering detailed, actionable security insights.</div><a class=readmore href=/posts/threat_modelling_with_fabric_framework/>Read more ⟶</a></section><section class=list-item><h1 class=title><a href=/posts/leveraging-llms-for-threat-modelling-claude-3-vs-gpt-4/>Leveraging LLMs for Threat Modeling - Claude 3 Opus vs GPT-4</a></h1><time>Mar 20, 2024</time><br><div class=description>With new version of Claude model, I would like to compare it to GPT-4 in threat modeling.</div><a class=readmore href=/posts/leveraging-llms-for-threat-modelling-claude-3-vs-gpt-4/>Read more ⟶</a></section><section class=list-item><h1 class=title><a href=/posts/review_your_architecture_using_llms/>Reviewing Your Architecture Using LLMs</a></h1><time>Oct 25, 2023</time><br><div class=description>The quality of input data is crucial for LLMs to perform effectively. Learn how you can use these LLMs to improve your architectural descriptions. Explore the new feature in my ai-threat-modeling-action GitHub action.</div><a class=readmore href=/posts/review_your_architecture_using_llms/>Read more ⟶</a></section><ul class=pagination><span class="page-item page-prev"></span><span class="page-item page-next"><a href=/page/2/ class=page-link aria-label=Next><span aria-hidden=true>Next →</span></a></span></ul></main><footer><div style=display:flex><a class=soc href=https://github.com/xvnpw rel=me title=GitHub><svg class="feather"><use href="/svg/feather-sprite.51cf5647cb1987f769b616558f2620fd9423d72058490231b391bf6aa3744b55.svg#github"/></svg></a><a class=border></a><a class=soc href=https://twitter.com/xvnpw rel=me title=Twitter><svg class="feather"><use href="/svg/feather-sprite.51cf5647cb1987f769b616558f2620fd9423d72058490231b391bf6aa3744b55.svg#twitter"/></svg></a><a class=border></a><a class=soc href=https://www.linkedin.com/in/marcin-niemiec-304349104/ rel=me title=Linkedin><svg class="feather"><use href="/svg/feather-sprite.51cf5647cb1987f769b616558f2620fd9423d72058490231b391bf6aa3744b55.svg#linkedin"/></svg></a><a class=border></a></div><div class=footer-info>2025 <a href=https://github.com/athul/archie>Archie Theme</a> | Built with <a href=https://gohugo.io>Hugo</a></div></footer><script async src="https://www.googletagmanager.com/gtag/js?id=G-YHETMXZXMZ"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-YHETMXZXMZ")}</script></div></body></html>