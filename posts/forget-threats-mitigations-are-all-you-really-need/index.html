<!doctype html><html><head lang=en><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Forget Threats, Mitigations are All You REALLY Need - xvnpw personal blog</title><link rel=icon type=image/png href=/favicon.png><meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="A practical perspective shift for security professionals: Learn why focusing on concrete mitigations rather than abstract threats leads to better developer engagement and more secure software. Featuring hands-on examples using AI-powered security analysis tools and real-world project implementations."><meta property="og:image" content><meta property="og:url" content="https://xvnpw.github.io/posts/forget-threats-mitigations-are-all-you-really-need/"><meta property="og:site_name" content="xvnpw personal blog"><meta property="og:title" content="Forget Threats, Mitigations are All You REALLY Need"><meta property="og:description" content="A practical perspective shift for security professionals: Learn why focusing on concrete mitigations rather than abstract threats leads to better developer engagement and more secure software. Featuring hands-on examples using AI-powered security analysis tools and real-world project implementations."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-02-02T09:00:00+01:00"><meta property="article:modified_time" content="2025-02-02T09:00:00+01:00"><meta property="article:tag" content="Security"><meta property="article:tag" content="Ai"><meta property="article:tag" content="Threat-Modeling"><meta property="article:tag" content="Flask"><meta property="article:tag" content="Github"><meta property="article:tag" content="Llm"><meta name=twitter:card content="summary"><meta name=twitter:title content="Forget Threats, Mitigations are All You REALLY Need"><meta name=twitter:description content="A practical perspective shift for security professionals: Learn why focusing on concrete mitigations rather than abstract threats leads to better developer engagement and more secure software. Featuring hands-on examples using AI-powered security analysis tools and real-world project implementations."><script src=https://xvnpw.github.io/js/feather.min.js></script><link href=https://xvnpw.github.io/css/fonts.2c2227b81b1970a03e760aa2e6121cd01f87c88586803cbb282aa224720a765f.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://xvnpw.github.io/css/main.5cebd7d4fb2b97856af8d32a6def16164fcf7d844e98e236fcb3559655020373.css><link id=darkModeStyle rel=stylesheet type=text/css href=https://xvnpw.github.io/css/dark.d22e2a2879d933a4b781535fc4c4c716e9f9d35ea4986dd0cbabda82effc4bdd.css media="(prefers-color-scheme: dark)"><link rel=stylesheet type=text/css href=https://xvnpw.github.io/css/my.12f12ddc55df9b20e3e0eab2e28f7afe86b15b1539c5dce5ef48f32ac5a1dd99.css></head><body><div class=content><header><div class=main><a href=https://xvnpw.github.io/>xvnpw personal blog</a></div><nav><a href=/>Home</a>
<a href=/posts>All posts</a>
<a href=/about>About</a>
<a href=/tags>Tags</a></nav></header><main><article><div class=title><h1 class=title>Forget Threats, Mitigations are All You REALLY Need</h1><div class=meta>Posted on Feb 2, 2025</div></div><section class=body><p>Ever feel like you&rsquo;re speaking a different language when you talk to developers about security? You&rsquo;re buzzing with threat models, attack vectors, and vulnerabilities, while they&rsquo;re focused on features, deadlines, and, well, <em>making things work</em>. I get it. I&rsquo;ve been there. And recently, I had a bit of an &ldquo;aha!&rdquo; moment that completely shifted my perspective on security discussions.</p><p>It happened during a review of security analysis with my colleagues at Form3. We were diving deep into the <a href=https://github.com/form3tech-oss/terraform-provider-chronicle>terraform-provider-chronicle</a> project (you can see analysis <a href=https://github.com/xvnpw/ai-security-analyzer/tree/main/examples/form3tech-oss/README.md>here</a>, using my <a href=https://github.com/xvnpw/ai-security-analyzer>ai-security-analyzer</a> tool). As we talked through AI generated threats, it struck me: to make AI tools useful for developers, we need to focus on mitigations, not threats. Developers are less interested in abstract threats and far more engaged when you talk about <strong>mitigations</strong> - concrete steps to <em>fix</em> things.</p><p>This wasn&rsquo;t a completely new idea, but this time it really clicked. I&rsquo;d been using AI to generate threat models, asking Large Language Models (LLMs) to identify threats and <em>then</em> suggest mitigations. But a question popped into my head: What if I flipped the script? What if I asked the LLM for <strong>mitigations directly</strong>, and <em>then</em> explored the threats those mitigations address?</p><p>Guess what—it works!</p><figure class=image-center><img src=https://github.com/user-attachments/assets/76ad96e6-ed5f-4d40-8565-00712f46beeb width=400></figure><h2 id=how-to-use-this-approach>How to Use This Approach</h2><p>In <a href=https://github.com/xvnpw/ai-security-analyzer>ai-security-analyzer</a> you can use <code>--agent-prompt-type mitigations</code> to generate mitigations, like this:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python ai_security_analyzer/app.py <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    dir <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    -t ../path/to/project <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    -o mitigations.md <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --agent-prompt-type mitigations <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --agent-provider google <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --agent-model gemini-2.0-flash-thinking-exp <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --agent-temperature <span style=color:#ae81ff>0</span>
</span></span></code></pre></div><h3 id=choosing-the-right-model>Choosing the Right Model</h3><p>It&rsquo;s best to use any reasoning models, like Gemini 2.0 Flash Thinking Experimental, or OpenAI&rsquo;s <code>o-family</code>. You can use DeepSeek R1, but it&rsquo;s not as good as those mentioned before.</p><h2 id=practical-example>Practical Example</h2><p>Let&rsquo;s see this in action! I put it to the test on the <a href=https://github.com/abi/screenshot-to-code>screenshot-to-code</a> project. The results were impressive. Here&rsquo;s a snippet focusing on Input Validation and Sanitization – notice how it breaks down <em>exactly</em> what needs to be done and <em>why</em> it matters:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-markdown data-lang=markdown><span style=display:flex><span><span style=color:#66d9ef>-</span> Mitigation Strategy: Input Validation and Sanitization
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>-</span> Description:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>1.</span> <span style=font-weight:700>**File Path Validation:**</span> In <span style=color:#e6db74>`evals.py`</span>, thoroughly validate user-provided folder paths to prevent path traversal vulnerabilities. Ensure paths are within expected directories and sanitize input to remove malicious characters.
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>2.</span> <span style=font-weight:700>**Limit Input File Sizes:**</span> Implement limits on the size of uploaded screenshots and video files in <span style=color:#e6db74>`generate_code.py`</span> and <span style=color:#e6db74>`video/utils.py`</span> to prevent excessively large files that could cause resource exhaustion or DoS.
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>3.</span> <span style=font-weight:700>**File Type Validation:**</span> Validate the file types of uploaded images and videos to ensure they are expected formats (e.g., PNG, JPG, MOV, MP4) in <span style=color:#e6db74>`generate_code.py`</span> and <span style=color:#e6db74>`video/utils.py`</span>.
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>4.</span> <span style=font-weight:700>**Image/Video Processing Limits:**</span> Implement safeguards in image/video processing functions (<span style=color:#e6db74>`image_processing/utils.py`</span>, <span style=color:#e6db74>`video/utils.py`</span>) to prevent processing of maliciously crafted files that could exploit vulnerabilities in image/video libraries (e.g., Pillow, moviepy). Consider using secure processing libraries and keeping them updated.
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>5.</span> <span style=font-weight:700>**URL Validation:**</span> In <span style=color:#e6db74>`screenshot.py`</span>, validate the input URL to <span style=color:#e6db74>`capture_screenshot`</span> to prevent unexpected behavior or SSRF vulnerabilities. Use a URL parsing library to ensure the URL is well-formed and potentially restrict allowed schemes (e.g., <span style=color:#e6db74>`http`</span>, <span style=color:#e6db74>`https`</span>).
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>6.</span> <span style=font-weight:700>**Content Security Policy (CSP):**</span> Implement a Content Security Policy in the frontend to mitigate potential XSS risks if the generated code is directly rendered in the application.
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>-</span> Threats Mitigated:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>-</span> Path Traversal (Medium Severity): Prevents attackers from accessing files outside of the intended directories in <span style=color:#e6db74>`evals.py`</span>.
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>-</span> Denial of Service (DoS) (Medium Severity): Prevents resource exhaustion from processing excessively large files or maliciously crafted files.
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>-</span> Code Injection (Indirect) (Low to Medium Severity): Reduces the risk of vulnerabilities in generated code by limiting input types and sizes, and through CSP (though indirect).
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>-</span> Server-Side Request Forgery (SSRF) (Low Severity): Reduces the risk of unintended external requests via <span style=color:#e6db74>`screenshot.py`</span>.
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>-</span> Impact:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>-</span> Path Traversal: Medium reduction in risk. Prevents unauthorized file access.
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>-</span> Denial of Service (DoS): Low to Medium reduction in risk. Makes it harder to cause resource exhaustion through malicious inputs.
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>-</span> Code Injection (Indirect): Low reduction in risk. Provides a layer of defense against potential vulnerabilities in generated code.
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>-</span> Server-Side Request Forgery (SSRF): Low reduction in risk. Limits the scope of potential SSRF issues.
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>-</span> Currently Implemented:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>-</span> Not explicitly implemented. File path validation, file type validation and size limits are not evident in the provided files. <span style=color:#e6db74>`image_processing/utils.py`</span> and <span style=color:#e6db74>`video/utils.py`</span> exist for image/video processing, but security aspects are not detailed. URL validation in <span style=color:#e6db74>`screenshot.py`</span> is missing.
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>-</span> Missing Implementation:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>-</span> File path validation in <span style=color:#e6db74>`evals.py`</span>.
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>-</span> Input file size limits in <span style=color:#e6db74>`generate_code.py`</span> and <span style=color:#e6db74>`video/utils.py`</span>.
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>-</span> File type validation in <span style=color:#e6db74>`generate_code.py`</span> and <span style=color:#e6db74>`video/utils.py`</span>.
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>-</span> Security review of image/video processing logic and libraries in <span style=color:#e6db74>`image_processing/utils.py`</span> and <span style=color:#e6db74>`video/utils.py`</span>.
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>-</span> URL validation in <span style=color:#e6db74>`screenshot.py`</span>.
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>-</span> Content Security Policy (CSP) implementation in frontend.
</span></span></code></pre></div><p>I was genuinely impressed with the detail and actionable insights from Gemini 2.0 Flash Thinking Experimental. It&rsquo;s a significant step up in terms of practical security guidance. You can explore the complete output <a href=https://github.com/xvnpw/ai-security-analyzer/blob/main/examples/dir-mitigations-screenshot-to-code-gemini-2.0-flash-thinking-exp.md>here</a> and see the full range of mitigation strategies it identified.</p><h2 id=crafting-effective-prompt>Crafting Effective Prompt</h2><p>You might be surprised at how straightforward the prompt is. Inspired by my experience from <a href=https://xvnpw.github.io/posts/scaling-threat-modeling-with-ai/>Scaling Threat Modeling with AI: Generating 1000 Threat Models Using Gemini 2.0 and AI Security Analyzer</a>, I&rsquo;ve learned that reasoning models thrive on clear, open-ended questions. Here&rsquo;s the prompt I used:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>You are cybersecurity expert, working with development team that is building application described in PROJECT FILES. Your task is to create mitigation strategies for application from PROJECT FILES. Focus on mitigation strategies for threats introduced by application from PROJECT FILES and omit general, common mitigation strategies. Use valid markdown formatting. Don&#39;t use markdown tables at all, use markdown lists instead. Create mitigation strategies list with: mitigation strategy, description (describe in details step by step how can developers or users reduce the risk), list of threats mitigated (describe what threats are mitigated and what is their severity), impact (describe the impact of the mitigation strategy - how much risk is reduced for each threat), currently implemented (describe if this mitigation strategy is currently implemented in the project and where), missing implementation (describe where this mitigation strategy is missing in the project). I will give you PROJECT FILES and CURRENT MITIGATION STRATEGIES. When the CURRENT MITIGATION STRATEGIES is not empty, it indicates that a draft of this document was created in previous interactions using earlier batches of PROJECT FILES. In this case, integrate new findings from current PROJECT FILES into the existing CURRENT MITIGATION STRATEGIES. Ensure consistency and avoid duplication. If the CURRENT MITIGATION STRATEGIES is empty, proceed to create a new mitigation strategies based on the current PROJECT FILES. The PROJECT FILES will contain typical files found in a GitHub repository, such as configuration files, scripts, README files, production code, testing code, and more.
</span></span></code></pre></div><h2 id=sec-docs-update>sec-docs Update</h2><p>I&rsquo;ve updated the <a href=https://github.com/xvnpw/sec-docs>sec-docs</a> repository with new mitigations for 1,000 projects. You can browse through language-specific folders or look for specific projects:</p><figure class=image-center><img src=https://github.com/user-attachments/assets/35179ffd-c852-4398-bc2c-a0ee8c90de01></figure><p>I will soon update sec-docs with the latest version of Gemini 2.0 Flash Thinking Experimental model, which extended its knowledge cutoff date to August 2024.</p><h2 id=summary>Summary</h2><p>This journey has shifted my perspective significantly. As someone who previously focused heavily on threats, vulnerabilities, and hacks, I initially found it challenging to accept that threat models might not be the primary focus. However, after implementing threat modeling programs across various organizations, my viewpoint has evolved. I&rsquo;ve realized something crucial: <strong>perfect threat models don&rsquo;t ship secure software</strong>.</p><p>While the security industry offers extensive resources for threat modeling - manifesto, capabilities, maturity models, and numerous expert presentations - we often hit roadblocks when trying to integrate these into development workflows. It&rsquo;s not about blaming developers; it&rsquo;s about recognizing that <strong>change is hard</strong>, especially when it feels abstract or disconnected from immediate tasks.</p><p>For those building application security programs, I offer two key suggestions:</p><ol><li>Focus on mitigations. It becomes easier to accept imperfectly formatted threat models when you know developers are actively preventing security issues.</li><li>Read &ldquo;Application Security Program Handbook&rdquo; by Derek Fisher for practical program management advice.</li></ol><p>Ultimately, security isn&rsquo;t about finding all the threats; it&rsquo;s about building robust defenses.</p><h2 id=post-scriptum>Post Scriptum</h2><p>This article should have been about AI-powered security analysis tools 🤖. However, I wanted to share my personal experience and shift in perspective. If you struggle on your cybersecurity journey, I hope this article will help you to find a new way to approach it. I was not aim to spark holly war ⚔️ on what is more important - threats or mitigations.</p><hr><p>Thanks for reading! You can contact me and/or follow me on <a href=https://x.com/xvnpw>X</a> and <a href=www.linkedin.com/in/marcin-niemiec-304349104>LinkedIn</a>.</p></section><div class=post-tags><nav class="nav tags"><ul class=tags><li><a href=/tags/security>security</a></li><li><a href=/tags/ai>ai</a></li><li><a href=/tags/threat-modeling>threat modeling</a></li><li><a href=/tags/flask>flask</a></li><li><a href=/tags/github>github</a></li><li><a href=/tags/llm>llm</a></li></ul></nav></div></article></main><footer><div style=display:flex><a class=soc href=https://github.com/xvnpw rel=me title=GitHub><i data-feather=github></i></a>
<a class=border></a><a class=soc href=https://twitter.com/xvnpw rel=me title=Twitter><i data-feather=twitter></i></a>
<a class=border></a><a class=soc href=https://www.linkedin.com/in/marcin-niemiec-304349104/ rel=me title=Linkedin><i data-feather=linkedin></i></a>
<a class=border></a></div><div class=footer-info>2025 <a href=https://github.com/athul/archie>Archie Theme</a> | Built with <a href=https://gohugo.io>Hugo</a></div></footer><script async src="https://www.googletagmanager.com/gtag/js?id=G-YHETMXZXMZ"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-YHETMXZXMZ")}</script><script>feather.replace()</script></div></body></html>