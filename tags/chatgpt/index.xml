<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Chatgpt on xvnpw personal blog</title><link>https://xvnpw.github.io/tags/chatgpt/</link><description>Recent content in Chatgpt on xvnpw personal blog</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sun, 18 May 2025 07:59:02 +0100</lastBuildDate><atom:link href="https://xvnpw.github.io/tags/chatgpt/index.xml" rel="self" type="application/rss+xml"/><item><title>Threat Modeling with LLMs: Two Years In - Hype, Hope, and a Look at Gemini 2.5 Pro</title><link>https://xvnpw.github.io/posts/threat-modeling-with-llms-two-years-in-hype-hope-and-a-look-at-gemini-2.5-pro/</link><pubDate>Sun, 18 May 2025 07:59:02 +0100</pubDate><guid>https://xvnpw.github.io/posts/threat-modeling-with-llms-two-years-in-hype-hope-and-a-look-at-gemini-2.5-pro/</guid><description>&lt;p>It&amp;rsquo;s been nearly two years since I began exploring how AI can enhance threat modeling processes. In this post, I&amp;rsquo;ll share my latest findings with Gemini 2.5 Pro Preview, one of the newest advanced models, and reflect on how AI systems have evolved during this period. More importantly, I&amp;rsquo;ll examine whether they&amp;rsquo;re fulfilling their initial promise for security threat modeling applications.&lt;/p>
&lt;figure class="image-center">&lt;img src="https://xvnpw.github.io/threat-modeling-with-llms-two-years-in-hype-hope-and-a-look-at-gemini-2.5-pro.png" width="400">
&lt;/figure>

&lt;h2 id="the-experiment-testing-gemini-25-pro">The Experiment: Testing Gemini 2.5 Pro&lt;/h2>
&lt;p>As with my previous research, the goal is to assess how effectively LLMs can assist in threat modeling. For this, I used a deliberately underspecified architecture for a fictional project: &amp;ldquo;AI Nutrition Pro&amp;rdquo;.&lt;/p></description></item></channel></rss>