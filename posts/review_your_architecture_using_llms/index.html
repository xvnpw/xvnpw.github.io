<!doctype html><html><head lang=en><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Reviewing Your Architecture Using LLMs - xvnpw personal blog</title><link rel=icon type=image/png href=/favicon.png><meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="The quality of input data is crucial for LLMs to perform effectively. Learn how you can use these LLMs to improve your architectural descriptions. Explore the new feature in my ai-threat-modeling-action GitHub action."><meta property="og:image" content><meta property="og:url" content="https://xvnpw.github.io/posts/review_your_architecture_using_llms/"><meta property="og:site_name" content="xvnpw personal blog"><meta property="og:title" content="Reviewing Your Architecture Using LLMs"><meta property="og:description" content="The quality of input data is crucial for LLMs to perform effectively. Learn how you can use these LLMs to improve your architectural descriptions. Explore the new feature in my ai-threat-modeling-action GitHub action."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-10-25T08:59:02+01:00"><meta property="article:modified_time" content="2023-10-25T08:59:02+01:00"><meta property="article:tag" content="Security"><meta property="article:tag" content="Threat-Modeling"><meta property="article:tag" content="Langchain"><meta property="article:tag" content="Llm"><meta property="article:tag" content="Gpt"><meta property="article:tag" content="Architecture"><meta name=twitter:card content="summary"><meta name=twitter:title content="Reviewing Your Architecture Using LLMs"><meta name=twitter:description content="The quality of input data is crucial for LLMs to perform effectively. Learn how you can use these LLMs to improve your architectural descriptions. Explore the new feature in my ai-threat-modeling-action GitHub action."><link href=https://xvnpw.github.io/css/fonts.2c2227b81b1970a03e760aa2e6121cd01f87c88586803cbb282aa224720a765f.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://xvnpw.github.io/css/main.6a0f23ea50fd34b46fee262a5a68e17d458c51a2bc99ba1ba018065de6b180c3.css><link id=darkModeStyle rel=stylesheet type=text/css href=https://xvnpw.github.io/css/dark.50b57e12d401420df23965fed157368aba37b76df0ecefd0b1ecd4da664f01a0.css media="(prefers-color-scheme: dark)"><link rel=stylesheet type=text/css href=https://xvnpw.github.io/css/my.6e08ae20ebbcf10b8953bc0c3935a825ae172c99096f9af1bf2df91a6d21a1be.css></head><body><div class=content><header><div class=main><a href=https://xvnpw.github.io/>xvnpw personal blog</a></div><nav><a href=/>Home</a>
<a href=/posts>All posts</a>
<a href=/about>About</a>
<a href=/tags>Tags</a></nav></header><main><article><div class=post-container><div class=post-content><div class=title><h1 class=title>Reviewing Your Architecture Using LLMs</h1><div class=meta>Posted on Oct 25, 2023</div></div><section class=body><p>Recently, I&rsquo;ve discussed <a href=https://xvnpw.github.io/posts/leveraging-llms-for-threat-modelling-gpt-3.5-vs-claude2-vs-gpt-4/>utilizing LLMs for threat modeling</a>. Building on that, I&rsquo;ve incorporated a new feature in my <a href=https://github.com/xvnpw/ai-threat-modeling-action>ai-threat-modeling-action</a> on GitHub. It now allows you to review your project&rsquo;s architectural description using LLMs. Let&rsquo;s delve deeper ü§ø!</p><h2 id=revisiting-the-experiment>Revisiting the Experiment</h2><p>For a detailed understanding of the experiment&rsquo;s structure, you can revisit my <a href=https://xvnpw.github.io/posts/leveraging-llms-for-threat-modelling-gpt-3.5/>previous post</a>. However, here&rsquo;s a brief summary:</p><p>I utilized markdown files, which described a fictional project named <strong>AI Nutrition-Pro</strong>, as input:</p><ul><li><a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt4/blob/main/ARCHITECTURE.md>ARCHITECTURE.md</a> - providing the architectural overview.</li></ul><p>The AI model was then assigned to threat modeling, resulting in this <a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt4/blob/main/ARCHITECTURE_SECURITY.md>output</a>.</p><h2 id=the-importance-of-documentation>The Importance of Documentation</h2><figure class=image-center><img src=https://github.com/xvnpw/xvnpw.github.io/assets/17719543/43a36068-a828-4e68-8b68-9fe48fead75f></figure><p>If a meme exists, it likely holds a kernel of truth üòè The challenge we face is that LLMs occasionally &ldquo;hallucinate,&rdquo; meaning they fabricate information. And they often do so with high confidence. It&rsquo;s somewhat akin to a student attempting to bluff their way through a question they&rsquo;re unsure about.</p><p>Reducing these hallucinations is tricky. While some models might be more susceptible than others, the probability of hallucination rises if LLMs receive insufficient input. This is the issue we aim to tackle.</p><p>For <a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt4/blob/main/ARCHITECTURE_SECURITY.md>threat modeling</a>, the primary input is the <a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt4/blob/main/ARCHITECTURE.md>project&rsquo;s architectural documentation</a>. So, how do we ensure its quality?</p><h2 id=reviewing-architecture-using-llm>Reviewing Architecture Using LLM</h2><p>I&rsquo;ve integrated the review feature into <a href=https://github.com/xvnpw/ai-threat-modeling-action>ai-threat-modeling-action</a>. The prompt is straightforward:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>Instruction:
</span></span><span style=display:flex><span>You are solution architect. I will provide you Architecture Description and you will:
</span></span><span style=display:flex><span>- Review the provided Architecture Description.
</span></span><span style=display:flex><span>- Identify areas that require improvement or further clarification.
</span></span><span style=display:flex><span>- Point out mistakes, things to improve
</span></span><span style=display:flex><span>- Give advices on how to make it more readable and robust
</span></span><span style=display:flex><span>- Pose questions or identify default assumptions, if any.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Architecture Description:
</span></span><span style=display:flex><span>&#34;{text}&#34;
</span></span></code></pre></div><p>An example output could look like:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-gdscript3 data-lang=gdscript3><span style=display:flex><span><span style=color:#75715e># (AI Generated) Architecture Review</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>The architecture description is well<span style=color:#f92672>-</span>detailed <span style=color:#f92672>and</span> provides a good understanding of the system<span style=color:#f92672>.</span> However, there are a few areas that could be improved <span style=color:#f92672>or</span> clarified:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1.</span> <span style=color:#f92672>**</span>Security<span style=color:#f92672>**</span>: The document does <span style=color:#f92672>not</span> mention any security measures<span style=color:#f92672>.</span> It<span style=color:#e6db74>&#39;s important to include details about how the system will be secured, such as encryption of data at rest and in transit, secure access controls, and secure application development practices.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2.</span> <span style=color:#f92672>**</span>Scalability <span style=color:#f92672>and</span> <span style=color:#a6e22e>Performance</span><span style=color:#f92672>**</span>: The document does <span style=color:#f92672>not</span> provide information on how the system will handle increased load <span style=color:#f92672>or</span> how it will perform under stress<span style=color:#f92672>.</span> It would be beneficial to include details about load balancing, auto<span style=color:#f92672>-</span>scaling, <span style=color:#f92672>and</span> performance monitoring<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3.</span> <span style=color:#f92672>**</span>Disaster Recovery <span style=color:#f92672>and</span> High Availability<span style=color:#f92672>**</span>: The document does <span style=color:#f92672>not</span> mention any strategies <span style=color:#66d9ef>for</span> disaster recovery <span style=color:#f92672>or</span> high availability<span style=color:#f92672>.</span> It would be helpful to include details about backup <span style=color:#f92672>and</span> restore procedures, failover strategies, <span style=color:#f92672>and</span> how the system will ensure data integrity<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>...</span>
</span></span></code></pre></div><p><code>{text}</code> is a placeholder for the architecture description from the file.</p><p>For a step-by-step guide on setting up the review as a continuous process in GitHub, visit <a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt4/blob/main/.github/workflows/architecture-ai-review.yml>here</a>.</p><h3 id=command-line>Command Line</h3><p>I&rsquo;ve recently refactored the source code of my action and extracted its Python scripts. This led to a new repository <a href=https://github.com/xvnpw/ai-threat-modeling>xvnpw/ai-threat-modeling</a>, which is command-line accessible.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ python ai-tm.py architecture --review --inputs &lt;path_to_project&gt;/ARCHITECTURE.md --output ARCHITECTURE_REVIEW.md --verbose
</span></span><span style=display:flex><span>INFO:root:review of architecture started...
</span></span><span style=display:flex><span>INFO:root:finished waiting on llm response
</span></span><span style=display:flex><span>INFO:root:response written to file
</span></span></code></pre></div><h3 id=chatgpt>ChatGPT</h3><p>For an applied example, you can view an <a href=https://chat.openai.com/share/70df15bd-551d-47f2-9c55-731f4aae4ed1>example review</a> in ChatGPT.</p><h2 id=conclusion>Conclusion</h2><p>Quality input data is vital for the optimal performance of LLMs. Why not utilize the same LLMs to refine your data? Experiment with my review action, scripts, or prompts and share your experience!</p><hr><p>Thank you for reading! Connect with me or follow me on <a href=https://twitter.com/xvnpw>X/Twitter</a>.</p></section><div class=post-tags><nav class="nav tags"><ul class=tags><li><a href=/tags/security>security</a></li><li><a href=/tags/threat-modeling>threat-modeling</a></li><li><a href=/tags/langchain>langchain</a></li><li><a href=/tags/llm>llm</a></li><li><a href=/tags/gpt>gpt</a></li><li><a href=/tags/architecture>architecture</a></li></ul></nav></div></div></div></article></main><footer><div style=display:flex><a class=soc href=https://github.com/xvnpw rel=me title=GitHub><svg class="feather"><use href="/svg/feather-sprite.51cf5647cb1987f769b616558f2620fd9423d72058490231b391bf6aa3744b55.svg#github"/></svg></a><a class=border></a><a class=soc href=https://twitter.com/xvnpw rel=me title=Twitter><svg class="feather"><use href="/svg/feather-sprite.51cf5647cb1987f769b616558f2620fd9423d72058490231b391bf6aa3744b55.svg#twitter"/></svg></a><a class=border></a><a class=soc href=https://www.linkedin.com/in/marcin-niemiec-304349104/ rel=me title=Linkedin><svg class="feather"><use href="/svg/feather-sprite.51cf5647cb1987f769b616558f2620fd9423d72058490231b391bf6aa3744b55.svg#linkedin"/></svg></a><a class=border></a></div><div class=footer-info>2025 <a href=https://github.com/athul/archie>Archie Theme</a> | Built with <a href=https://gohugo.io>Hugo</a></div></footer><script async src="https://www.googletagmanager.com/gtag/js?id=G-YHETMXZXMZ"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-YHETMXZXMZ")}</script></div></body></html>