<!doctype html><html><head lang=en><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Leveraging LLMs for Threat Modeling - GPT-3.5 - xvnpw personal blog</title><link rel=icon type=image/png href=/favicon.png><meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="In this article, I delve into the AI Nutrition-Pro experiment, a research project exploring the potential of LLMs in enhancing security practices during the design phase of DevSecOps: threat modeling and security review."><meta property="og:image" content><meta property="og:url" content="https://xvnpw.github.io/posts/leveraging-llms-for-threat-modelling-gpt-3.5/"><meta property="og:site_name" content="xvnpw personal blog"><meta property="og:title" content="Leveraging LLMs for Threat Modeling - GPT-3.5"><meta property="og:description" content="In this article, I delve into the AI Nutrition-Pro experiment, a research project exploring the potential of LLMs in enhancing security practices during the design phase of DevSecOps: threat modeling and security review."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-08-17T18:59:02+01:00"><meta property="article:modified_time" content="2023-08-17T18:59:02+01:00"><meta property="article:tag" content="Security"><meta property="article:tag" content="Threat-Modeling"><meta property="article:tag" content="Langchain"><meta property="article:tag" content="Llm"><meta property="article:tag" content="Gpt"><meta name=twitter:card content="summary"><meta name=twitter:title content="Leveraging LLMs for Threat Modeling - GPT-3.5"><meta name=twitter:description content="In this article, I delve into the AI Nutrition-Pro experiment, a research project exploring the potential of LLMs in enhancing security practices during the design phase of DevSecOps: threat modeling and security review."><link href=https://xvnpw.github.io/css/fonts.2c2227b81b1970a03e760aa2e6121cd01f87c88586803cbb282aa224720a765f.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://xvnpw.github.io/css/main.6a0f23ea50fd34b46fee262a5a68e17d458c51a2bc99ba1ba018065de6b180c3.css><link id=darkModeStyle rel=stylesheet type=text/css href=https://xvnpw.github.io/css/dark.50b57e12d401420df23965fed157368aba37b76df0ecefd0b1ecd4da664f01a0.css media="(prefers-color-scheme: dark)"><link rel=stylesheet type=text/css href=https://xvnpw.github.io/css/my.6e08ae20ebbcf10b8953bc0c3935a825ae172c99096f9af1bf2df91a6d21a1be.css></head><body><div class=content><header><div class=main><a href=https://xvnpw.github.io/>xvnpw personal blog</a></div><nav><a href=/>Home</a>
<a href=/posts>All posts</a>
<a href=/about>About</a>
<a href=/tags>Tags</a></nav></header><main><article><div class=post-container><div class=post-content><div class=title><h1 class=title>Leveraging LLMs for Threat Modeling - GPT-3.5</h1><div class=meta>Posted on Aug 17, 2023</div></div><section class=body><p>In this article, I delve into the <a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt3.5>AI Nutrition-Pro experiment</a>, a research project exploring the potential of LLMs in enhancing security practices during the design phase of DevSecOps: <strong>threat modeling</strong> and <strong>security review</strong>.</p><h2 id=devsecops-a-brief-overview>DevSecOps: A Brief Overview</h2><p>DevSecOps merges the principles of development, security, and operations to create a culture of shared responsibility for software security. The three main goals of DevSecOps are:</p><ul><li><strong>Shift Left Security:</strong> Identifying and addressing security vulnerabilities as early as possible in the software development lifecycle.</li><li><strong>Developer-Centric:</strong> Integrating security practices seamlessly into the developer&rsquo;s ecosystem, including Integrated Development Environments (IDEs), code hosting platforms, and pull requests.</li><li><strong>Fast Feedback and Guidance:</strong> Providing developers with rapid feedback on security issues and guidance on secure coding practices.</li></ul><p>While security tools like <a href=https://semgrep.dev/blog/2023/using-ai-to-write-secure-code-with-semgrep>semgrep</a> can already use LLMs in the coding phase, the AI Nutrition-Pro experiment seeks to explore the benefits of LLMs during the design phase, particularly in security design reviews and threat modeling.</p><h2 id=structure-of-experiment>Structure of Experiment</h2><p>I created <strong>fake</strong> input data as if it was real project in github repository and used github action <a href=https://github.com/xvnpw/ai-threat-modeling-action>xvnpw/ai-threat-modeling-action</a> to automatically generate output content and commit it directly into repository or create pull request. Action can also comment on issues.</p><h3 id=input-data>Input Data</h3><table><thead><tr><th>Name</th><th>File</th><th>Description</th><th>Security artefact to generate</th></tr></thead><tbody><tr><td>Project description</td><td><a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt3.5/blob/main/PROJECT.md>PROJECT.md</a></td><td>High level description of the project with business explanation and listed core features</td><td>High level security design review</td></tr><tr><td>Architecture</td><td><a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt3.5/blob/main/ARCHITECTURE.md>ARCHITECTURE.md</a></td><td>Architecture of the solution</td><td>Threat modeling</td></tr><tr><td>User story</td><td><a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt3.5/blob/main/user-stories/0001_STORE_DIET_INTRODUCTIONS.md>0001_STORE_DIET_INTRODUCTIONS.md</a></td><td>Technical and user stories to implement</td><td>Security related acceptance criteria</td></tr></tbody></table><h3 id=results>Results</h3><p>I will omit input data and only refer to it in repository (you can check it directly). In my opinion, the most interesting are comments on results and prompts.</p><h4 id=project-description>Project description</h4><p><strong>Input:</strong> <a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt3.5/blob/main/PROJECT.md>PROJECT.md</a>:</p><p><strong>Prompt</strong> is quite simple. First, I provided extensive instruction, and next example of output format, and at the end <code>PROJECT.md</code> content:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>Instruction:
</span></span><span style=display:flex><span>- You are a security architect.
</span></span><span style=display:flex><span>- Your task is to analyze project description and create high level security and privacy requirements
</span></span><span style=display:flex><span>- Project description will be in markdown format
</span></span><span style=display:flex><span>- Format output as markdown
</span></span><span style=display:flex><span>- Response with at least 10 high level security and privacy requirements formatted as markdown and nothing else
</span></span><span style=display:flex><span>- I will provide you example of requirement
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Example of requirement:
</span></span><span style=display:flex><span>### 1. Authentication and Authorization
</span></span><span style=display:flex><span>- **Requirement**: Implement strong authentication mechanisms for all users, applications, and APIs accessing AI Nutrition-Pro.
</span></span><span style=display:flex><span>- **Description**: Utilize secure authentication protocols such as OAuth 2.0 or JWT to authenticate and authorize tenants, dietitians, and other users. Different levels of access should be granted based on roles and responsibilities.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Project description:
</span></span><span style=display:flex><span>&#34;{text}&#34;
</span></span></code></pre></div><p><code>PROJECT.md</code> file is placed into the prompt in <code>{text}</code> placeholder.</p><p>GPT output is saved into <a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt3.5/blob/main/PROJECT_SECURITY.md>PROJECT_SECURITY.md</a>:</p><blockquote><h1 id=ai-generated-high-level-security-and-privacy-requirements>(AI Generated) High Level Security and Privacy Requirements</h1><h3 id=1-authentication-and-authorization>1. Authentication and Authorization</h3><ul><li><strong>Requirement</strong>: Implement secure authentication mechanisms for all users, applications, and APIs accessing AI Nutrition-Pro.</li><li><strong>Description</strong>: Utilize strong authentication protocols such as OAuth 2.0 or JWT to authenticate and authorize tenants, dietitians, and other users. Different levels of access should be granted based on roles and responsibilities.
&mldr;</li></ul></blockquote><p><strong>Comment on results:</strong></p><p>These requirements demonstrate a <strong>solid grasp</strong> of security best practices and compliance standards. They are good for high level description. Output could benefit from providing more specific implementation guidance or references to established security frameworks.</p><h4 id=architecture>Architecture</h4><p><strong>Input:</strong> <a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt3.5/blob/main/ARCHITECTURE.md>ARCHITECTURE.md</a></p><p>Architecture was described using <a href=https://c4model.com/>C4 Model</a>, with diagrams coded in <code>mermaid</code>. Additionally, each diagram was described in points in case GPT cannot understand it from <code>mermaid</code>.</p><p>This <strong>prompt</strong> is more complex. A simple instruction to perform threat model didn&rsquo;t return meaningful results üòï. After playing for some time with the prompt, I got good results using 2 stages:</p><ul><li>first I ask to list data flows for architecture</li><li>and then for each data flow I ask for threat modeling using STRIDE per component technique</li></ul><p>First prompt:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>Instruction:
</span></span><span style=display:flex><span>- You are a security architect
</span></span><span style=display:flex><span>- List data flows for all components that are internal and important for security of system
</span></span><span style=display:flex><span>- You should not include any persons in data flows
</span></span><span style=display:flex><span>- You should answer only in list and nothing more. Each data flow should be in separated line
</span></span><span style=display:flex><span>- Architecture description will be in markdown format
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Example:
</span></span><span style=display:flex><span>Data flow 1: Client -&gt; API Gateway 
</span></span><span style=display:flex><span>Data flow 2: API Gateway -&gt; API Application
</span></span><span style=display:flex><span>Data flow 3: API Application -&gt; API Database
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Architecture description:
</span></span><span style=display:flex><span>&#34;{text}&#34;
</span></span></code></pre></div><p><code>{text}</code> is placeholder for <code>ARCHITECTURE.md</code> file.</p><p>Second prompt (executed for each data flow):</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>Instruction:
</span></span><span style=display:flex><span>- You are a security architect
</span></span><span style=display:flex><span>- I will provide you Architecture description
</span></span><span style=display:flex><span>- Perform threat modeling using STRIDE per component technique for data flow
</span></span><span style=display:flex><span>- I will provide you data flow in structure: Data flow 1: Component A -&gt; Component B
</span></span><span style=display:flex><span>- You should answer only in table and nothing more
</span></span><span style=display:flex><span>- Architecture description will be in markdown format
</span></span><span style=display:flex><span>- Format output as markdown
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Output of threat modeling should be in table as in example:
</span></span><span style=display:flex><span>### Data flow 1: Component A -&gt; Component B
</span></span><span style=display:flex><span>| Threat Id | Component name | Threat Name | STRIDE category | Mitigations | Risk severity |
</span></span><span style=display:flex><span>| --- | --- | --- | --- | --- | --- |
</span></span><span style=display:flex><span>| 1 | Component A | Attacker is able to spoof client using leaked API key | Spoofing | Invalidation of API keys. Usage of request signing technique | Critical |
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Architecture description:
</span></span><span style=display:flex><span>&#34;{text}&#34;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Data flow:
</span></span><span style=display:flex><span>&#34;{dataflow}&#34;
</span></span></code></pre></div><p><code>{text}</code> is one more time placeholder for <code>ARCHITECTURE.md</code> and <code>{dataflow}</code> is placeholder for data flows returned in the previous step.</p><p>GPT output is saved into <a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt3.5/blob/main/ARCHITECTURE_SECURITY.md>ARCHITECTURE_SECURITY.md</a>:</p><blockquote><h1 id=ai-generated-architecture-threat-model>(AI Generated) Architecture Threat Model</h1><h3 id=data-flow-1-client---api-gateway>Data flow 1: Client -> API Gateway</h3><table><thead><tr><th>Threat Id</th><th>Component name</th><th>Threat Name</th><th>STRIDE category</th><th>Mitigations</th><th>Risk severity</th></tr></thead><tbody><tr><td>1</td><td>Client</td><td>Attacker intercepts and modifies requests/responses</td><td>Tampering</td><td>Use HTTPS for secure communication. Implement message integrity checks.</td><td>High</td></tr><tr><td>2</td><td>API Gateway</td><td>Attacker bypasses authentication and gains unauthorized access</td><td>Spoofing</td><td>Implement strong authentication mechanisms. Use secure protocols for communication.</td><td>High</td></tr></tbody></table><p>&mldr;</p></blockquote><p><strong>Comment on results:</strong></p><p>It was much harder to get meaningful results for threat modeling. For some runs with <a href=https://community.openai.com/t/cheat-sheet-mastering-temperature-and-top-p-in-chatgpt-api-a-few-tips-and-tricks-on-controlling-the-creativity-deterministic-output-of-prompt-responses/172683>temperature</a> > 0, I got brilliant results, but most of them were just <strong>average</strong>. They are still relevant to the scope, but <strong>very general</strong>. While the document presents a comprehensive threat model, some areas could benefit from additional elaboration. GPT had no problem with consistently following output structure of table.</p><h4 id=user-story>User story</h4><p><strong>Input:</strong> <a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt3.5/blob/main/user-stories/0001_STORE_DIET_INTRODUCTIONS.md>0001_STORE_DIET_INTRODUCTIONS.md</a></p><p>User story is the most detailed document. It contains new API structure, container diagram from C4 model, and listed tasks.</p><p><strong>Prompt</strong> also is the most complex. Same as for architecture threat model, I couldn&rsquo;t benefit from simple prompt üòû. It was returning acceptance criteria for elements that are out of scope, e.g. client. I suspect that reason of that is misunderstanding word &ldquo;component&rdquo; by GPT. Each time I ask for &ldquo;components in scope of user story&rdquo; it returned rubbish. I changed that into question for &ldquo;architecture containers, services or applications included in architecture&rdquo;. This worked way better than before. Still for some runs I saw <em>client</em>, but it was very rare.</p><p>As mentioned above prompt has two stages:</p><ul><li>first, I ask to list components (using &ldquo;architecture containers, services or applications included in architecture&rdquo;)</li><li>second, I ask to list security related acceptance criteria for every component - in contrast to architecture I don&rsquo;t ask for each component individually but all at once. This is due to fact that asking one by one generated a lot of acceptance criteria. Mostly not relevant üòè</li></ul><p>As this prompt is the most complex, please review it directly in <a href=https://github.com/xvnpw/ai-threat-modeling-action/blob/main/user_story.py>repository</a>.</p><p>GPT output is saved into <a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt3.5/blob/main/user-stories/0001_STORE_DIET_INTRODUCTIONS_SECURITY.md>0001_STORE_DIET_INTRODUCTIONS_SECURITY.md</a>:</p><blockquote><h1 id=ai-generated-security-related-acceptance-criteria>(AI Generated) Security Related Acceptance Criteria</h1><p>Based on the provided user story, architecture description, and architecture threat model, the following are the security-related acceptance criteria for the specified architecture containers, services, or applications:</p><p><strong>API Gateway:</strong></p><ul><li><strong>AC1:</strong> The API Gateway must enforce authentication mechanisms to prevent unauthorized access.</li><li><strong>AC2:</strong> The API Gateway must implement rate limiting and throttling mechanisms to mitigate the impact of excessive requests.</li><li><strong>AC3:</strong> The API Gateway must perform input validation and sanitization to prevent injection attacks.</li><li><strong>AC4:</strong> The API Gateway must use HTTPS for secure communication to prevent interception and tampering.</li></ul><p>&mldr;</p></blockquote><p><strong>Comment on results:</strong></p><p>Same as for architecture it was hard to get good results. For some of runs, I got brilliant output with reference to API path and parameters üî•. But for most of runs, I got very general and average results.</p><h2 id=summary>Summary</h2><p>GPT-3.5 has <strong>some potential</strong> for performing threat modeling and security reviews, especially for teams without security engineers and/or with junior staff. It gives <strong>general</strong> and <strong>high level</strong> guidance but <strong>lacks detailed descriptions</strong>. Prompt needs to be tuned to match document&rsquo;s structure.</p><p>I encourage you to try with <a href=https://github.com/xvnpw/ai-threat-modeling-action>xvnpw/ai-threat-modeling-action</a> for your documentation, and share the results!</p><p>In next part, I will review GPT-4.</p><hr><p>Thanks for reading! You can contact me and/or follow on <a href=https://twitter.com/xvnpw>X/Twitter</a>.</p></section><div class=post-tags><nav class="nav tags"><ul class=tags><li><a href=/tags/security>security</a></li><li><a href=/tags/threat-modeling>threat-modeling</a></li><li><a href=/tags/langchain>langchain</a></li><li><a href=/tags/llm>llm</a></li><li><a href=/tags/gpt>gpt</a></li></ul></nav></div></div></div></article></main><footer><div style=display:flex><a class=soc href=https://github.com/xvnpw rel=me title=GitHub><svg class="feather"><use href="/svg/feather-sprite.51cf5647cb1987f769b616558f2620fd9423d72058490231b391bf6aa3744b55.svg#github"/></svg></a><a class=border></a><a class=soc href=https://twitter.com/xvnpw rel=me title=Twitter><svg class="feather"><use href="/svg/feather-sprite.51cf5647cb1987f769b616558f2620fd9423d72058490231b391bf6aa3744b55.svg#twitter"/></svg></a><a class=border></a><a class=soc href=https://www.linkedin.com/in/marcin-niemiec-304349104/ rel=me title=Linkedin><svg class="feather"><use href="/svg/feather-sprite.51cf5647cb1987f769b616558f2620fd9423d72058490231b391bf6aa3744b55.svg#linkedin"/></svg></a><a class=border></a></div><div class=footer-info>2025 <a href=https://github.com/athul/archie>Archie Theme</a> | Built with <a href=https://gohugo.io>Hugo</a></div></footer><script async src="https://www.googletagmanager.com/gtag/js?id=G-YHETMXZXMZ"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-YHETMXZXMZ")}</script></div></body></html>