<!doctype html><html><head lang=en><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Leveraging LLMs for Threat Modeling - Claude 3 Opus vs GPT-4 - xvnpw personal blog</title><link rel=icon type=image/png href=/favicon.png><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="With new version of Claude model, I would like to compare it to GPT-4 in threat modeling."><meta property="og:image" content><meta property="og:url" content="https://xvnpw.github.io/posts/leveraging-llms-for-threat-modelling-claude-3-vs-gpt-4/"><meta property="og:site_name" content="xvnpw personal blog"><meta property="og:title" content="Leveraging LLMs for Threat Modeling - Claude 3 Opus vs GPT-4"><meta property="og:description" content="With new version of Claude model, I would like to compare it to GPT-4 in threat modeling."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-03-20T14:59:02+01:00"><meta property="article:modified_time" content="2024-03-20T14:59:02+01:00"><meta property="article:tag" content="Security"><meta property="article:tag" content="Threat-Modeling"><meta property="article:tag" content="Langchain"><meta property="article:tag" content="Llm"><meta property="article:tag" content="Gpt"><meta property="article:tag" content="Claude"><meta name=twitter:card content="summary"><meta name=twitter:title content="Leveraging LLMs for Threat Modeling - Claude 3 Opus vs GPT-4"><meta name=twitter:description content="With new version of Claude model, I would like to compare it to GPT-4 in threat modeling."><script src=https://xvnpw.github.io/js/feather.min.js></script><link href=https://xvnpw.github.io/css/fonts.2c2227b81b1970a03e760aa2e6121cd01f87c88586803cbb282aa224720a765f.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://xvnpw.github.io/css/main.5cebd7d4fb2b97856af8d32a6def16164fcf7d844e98e236fcb3559655020373.css><link id=darkModeStyle rel=stylesheet type=text/css href=https://xvnpw.github.io/css/dark.d22e2a2879d933a4b781535fc4c4c716e9f9d35ea4986dd0cbabda82effc4bdd.css media="(prefers-color-scheme: dark)"><link rel=stylesheet type=text/css href=https://xvnpw.github.io/css/my.3c46484c36967b544a264fefb69e90ef0756aacf691c82f058e0f58769499ad2.css></head><body><div class=content><header><div class=main><a href=https://xvnpw.github.io/>xvnpw personal blog</a></div><nav><a href=/>Home</a>
<a href=/posts>All posts</a>
<a href=/about>About</a>
<a href=/tags>Tags</a></nav></header><main><article><div class=title><h1 class=title>Leveraging LLMs for Threat Modeling - Claude 3 Opus vs GPT-4</h1><div class=meta>Posted on Mar 20, 2024</div></div><section class=body><p><a href=https://www.anthropic.com/news/claude-3-family>Claude 3 Opus</a> is the latest and most powerful model from Anthropic. Is it able to overcome GPT-4?</p><figure class=image-center><img src=https://github.com/xvnpw/xvnpw.github.io/assets/17719543/3305cef0-c07d-4239-8fd9-c6e9e14146e7></figure><h2 id=revisiting-the-experiment>Revisiting the Experiment</h2><p>If you wish to understand more about the experiment structure, you can refer to my <a href=https://xvnpw.github.io/posts/leveraging-llms-for-threat-modelling-gpt-3.5/>previous post</a>. But here&rsquo;s a quick recap:</p><p>I used markdown files describing a fictional project, <strong>AI Nutrition-Pro</strong>, with input:</p><ul><li><a href=https://github.com/xvnpw/ai-nutrition-pro-design-claude3-opus/blob/main/PROJECT.md>PROJECT.md</a> - high level project description</li><li><a href=https://github.com/xvnpw/ai-nutrition-pro-design-claude3-opus/blob/main/ARCHITECTURE.md>ARCHITECTURE.md</a> - architecture description</li><li><a href=https://github.com/xvnpw/ai-nutrition-pro-design-claude3-opus/blob/main/user-stories/0001_STORE_DIET_INTRODUCTIONS.md>0001_STORE_DIET_INTRODUCTIONS.md</a> - user story</li></ul><p>I tasked the AI models with four types of analysis: high-level security design review, threat modeling, security-related acceptance criteria and review of architecture:</p><ul><li>High level security design review: <a href=https://github.com/xvnpw/ai-nutrition-pro-design-claude3-opus/blob/main/PROJECT_SECURITY.md>Claude 3 Opus</a>, <a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt4/blob/main/PROJECT_SECURITY.md>GPT-4</a></li><li>Threat Modeling: <a href=https://github.com/xvnpw/ai-nutrition-pro-design-claude3-opus/blob/main/ARCHITECTURE_SECURITY.md>Claude 3 Opus</a>, <a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt4/blob/main/ARCHITECTURE_SECURITY.md>GPT-4</a></li><li>Security related acceptance criteria: <a href=https://github.com/xvnpw/ai-nutrition-pro-design-claude3-opus/blob/main/user-stories/0001_STORE_DIET_INTRODUCTIONS_SECURITY.md>Claude 3 Opus</a>, <a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt4/blob/main/user-stories/0001_STORE_DIET_INTRODUCTIONS_SECURITY.md>GPT-4</a></li><li>Review of architecture: <a href=https://github.com/xvnpw/ai-nutrition-pro-design-claude3-opus/blob/main/ARCHITECTURE_REVIEW.md>Claude 3 Opus</a>, <a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt4/blob/main/ARCHITECTURE_REVIEW.md>GPT-4</a></li></ul><h2 id=key-learnings>Key Learnings</h2><p>The latest models from OpenAI and Anthropic demonstrate significant advancements in threat modeling compared to their predecessors, GPT-3.5 and Claude 2. Key improvements include:</p><ul><li><strong>Enhanced Reasoning:</strong> These models exhibit stronger reasoning abilities when it comes to threats, allowing them to integrate additional context like existing security mitigations.</li><li><strong>Accurate Architecture Understanding:</strong> They demonstrate a better grasp of system architecture, correctly identifying individual components.</li><li><strong>JSON Compatibility:</strong> They work effectively with JSON formatting, making them suitable for integration with technical systems and data.</li></ul><h2 id=detailed-threats-comparison>Detailed threats comparison</h2><p>Let&rsquo;s check threats for first data flow, which is <code>Meal Planner -> API Gateway</code>: <a href=https://github.com/xvnpw/ai-nutrition-pro-design-claude3-opus/blob/main/ARCHITECTURE_SECURITY.md#data-flow-1-meal-planner---api-gateway-uses-for-ai-content-generation-httpsrest>Claude 3 Opus</a>, <a href=https://github.com/xvnpw/ai-nutrition-pro-design-gpt4/blob/main/ARCHITECTURE_SECURITY.md#data-flow-1-meal-planner-application---api-gateway>GPT-4</a></p><h3 id=spoofing>Spoofing</h3><table><thead><tr><th>Field</th><th>Claude 3 Opus</th><th>GPT-4</th><th>Comment</th></tr></thead><tbody><tr><td><strong>Threat Name</strong></td><td><code>Attacker bypasses weak authentication and gains unauthorized access to API Gateway</code></td><td><code>Attacker spoofs Meal Planner application and sends malicious requests to API Gateway</code></td><td>Similar</td></tr><tr><td><strong>Explanation</strong></td><td><code>If the authentication mechanism between the Meal Planner application and the API Gateway is weak or improperly implemented, an attacker could potentially bypass it and gain unauthorized access to the API Gateway.</code></td><td><code>The API Gateway is responsible for authenticating requests from the Meal Planner application. If an attacker can spoof the Meal Planner application, they can potentially send malicious requests to the API Gateway.</code></td><td>Similar</td></tr><tr><td><strong>How threat is already mitigated in architecture</strong></td><td><code>Partially mitigated. The architecture description states: "Authentication with Meal Planner applications - each has individual API key." This indicates that authentication is implemented using API keys. However, the strength and security of the API key mechanism are not specified.</code></td><td><code>The architecture description mentions that each Meal Planner application has an individual API key for authentication. This mitigates the threat to some extent, but it's not completely foolproof if the API key is compromised.</code></td><td>Claude 3 Opus better follow instruction here. It adds <em>Partially mitigated</em> which is mentioned in instruction. From technical perspective both answers are equal.</td></tr><tr><td><strong>Mitigations</strong></td><td><code>Ensure strong authentication mechanisms are in place, such as using secure and properly implemented API keys or OAuth tokens. Regularly rotate and revoke API keys. Implement rate limiting and monitoring to detect and prevent brute-force attempts.</code></td><td><code>Ensure strong authentication mechanisms are in place, such as using secure and properly implemented API keys or OAuth tokens. Regularly rotate and revoke API keys. Implement rate limiting and monitoring to detect and prevent brute-force attempts.</code></td><td>Similar</td></tr></tbody></table><h3 id=tampering>Tampering</h3><table><thead><tr><th>Field</th><th>Claude 3 Opus</th><th>GPT-4</th><th>Comment</th></tr></thead><tbody><tr><td><strong>Threat Name</strong></td><td><code>Attacker tampers with data sent from Meal Planner to API Gateway</code></td><td><code>Attacker intercepts and tampers with data between Meal Planner application and API Gateway</code></td><td>Similar</td></tr><tr><td><strong>Explanation</strong></td><td><code>If the communication channel between the Meal Planner application and the API Gateway is not properly secured, an attacker could intercept and modify the data being sent, potentially leading to unauthorized modifications or injection of malicious content.</code></td><td><code>The data transmitted between the Meal Planner application and the API Gateway could contain sensitive information. If an attacker can intercept and tamper with this data, it could lead to serious consequences.</code></td><td>Claude 3 Opus gives more specific answer</td></tr><tr><td><strong>How threat is already mitigated in architecture</strong></td><td><code>Mitigated. The architecture description states: "network traffic between Meal Planner applications and API Gateway is encrypted using TLS." This ensures the confidentiality and integrity of the data in transit.</code></td><td><code>The architecture description mentions that the network traffic between the Meal Planner application and the API Gateway is encrypted using TLS. This mitigates the threat by making it difficult for an attacker to read or modify the data during transmission.</code></td><td>Claude 3 Opus better follow instruction here. It adds <em>Mitigated</em> which is mentioned in instruction. From technical perspective both answers are equal.</td></tr><tr><td><strong>Mitigations</strong></td><td><code>Ensure proper implementation of TLS encryption for all communication between the Meal Planner application and the API Gateway. Use strong encryption algorithms and keep the TLS certificates up to date.</code></td><td><code>Regularly update and patch the TLS protocol to protect against known vulnerabilities. Also, implement a secure key management system to protect the encryption keys.</code></td><td>Similar</td></tr></tbody></table><h3 id=denial-of-service>Denial of Service</h3><p>GPT-4 didn&rsquo;t provide threat for this category.</p><table><thead><tr><th>Field</th><th>Claude 3 Opus</th><th>GPT-4</th><th>Comment</th></tr></thead><tbody><tr><td><strong>Threat Name</strong></td><td><code>Attacker floods API Gateway with requests, causing denial of service</code></td><td>-</td><td>Threat is valid</td></tr><tr><td><strong>Explanation</strong></td><td><code>If the API Gateway does not have proper rate limiting or protection against excessive requests, an attacker could flood it with a large number of requests, overwhelming its resources and causing a denial of service.</code></td><td>-</td><td>Valid</td></tr><tr><td><strong>How threat is already mitigated in architecture</strong></td><td><code>Partially mitigated. The architecture description mentions "rate limiting" as one of the responsibilities of the API Gateway. However, the specific implementation details and effectiveness of the rate limiting mechanism are not provided.</code></td><td>-</td><td>Valid. I like that model pointed out missing specifics of implementation of rate limiting.</td></tr><tr><td><strong>Mitigations</strong></td><td><code>Implement robust rate limiting mechanisms in the API Gateway to restrict the number of requests per client or IP address. Set appropriate thresholds and configure alerts for abnormal traffic patterns. Use cloud-based DDoS protection services for additional layer of defense.</code></td><td>-</td><td>Valid</td></tr></tbody></table><h3 id=elevation-of-privilege>Elevation of Privilege</h3><p>GPT-4 didn&rsquo;t provide threat for this category.</p><table><thead><tr><th>Field</th><th>Claude 3 Opus</th><th>GPT-4</th><th>Comment</th></tr></thead><tbody><tr><td><strong>Threat Name</strong></td><td><code>Attacker exploits vulnerabilities in API Gateway to gain unauthorized access or elevate privileges</code></td><td>-</td><td>Threat is valid</td></tr><tr><td><strong>Explanation</strong></td><td><code>If the API Gateway itself has vulnerabilities or misconfigurations, an attacker could potentially exploit them to gain unauthorized access to the system or elevate their privileges.</code></td><td>-</td><td>Valid</td></tr><tr><td><strong>How threat is already mitigated in architecture</strong></td><td><code>Not implemented. The architecture description does not provide information about the security measures implemented to protect the API Gateway itself from vulnerabilities or misconfigurations.</code></td><td>-</td><td>Valid</td></tr><tr><td><strong>Mitigations</strong></td><td><code>Regularly update and patch the API Gateway components. Perform security assessments and penetration testing to identify and address vulnerabilities. Implement strict access controls and least privilege principles for administrative access to the API Gateway.</code></td><td>-</td><td>Valid</td></tr></tbody></table><h2 id=the-verdict-claude-3-opus-vs-gpt-4>The Verdict: Claude 3 Opus vs. GPT-4</h2><p>Claude 3 Opus and GPT-4 are both powerful large language models (LLMs) capable of understanding context and generating meaningful threat assessments. In my testing, <strong>Claude 3 Opus performed slightly better, demonstrating a greater ability to identify threats and adhere closely to instructions.</strong></p><p>However, it&rsquo;s important to remember that LLM results can vary from execution to execution. Just as different humans have varying levels of threat modeling expertise (non-technical employees, cybersecurity interns, software developers, and cybersecurity experts), repeated trials might reveal slightly different performance between Claude 3 Opus and GPT-4.</p><p>Ultimately, can we accept minor hallucinations from the model? In threat modeling, I would argue <strong>yes</strong>. Software engineers, who are likely to be the ones requesting AI-generated threat models, can easily identify and correct implausible threats, adjusting their input accordingly.</p><p><a href=https://github.com/xvnpw/ai-threat-modeling-action>Code</a> used in this experiment is published on github.</p><hr><p>Thanks for reading! You can contact me and/or follow on <a href=https://twitter.com/xvnpw>X/Twitter</a>.</p></section><div class=post-tags><nav class="nav tags"><ul class=tags><li><a href=/tags/security>security</a></li><li><a href=/tags/threat-modeling>threat-modeling</a></li><li><a href=/tags/langchain>langchain</a></li><li><a href=/tags/llm>llm</a></li><li><a href=/tags/gpt>gpt</a></li><li><a href=/tags/claude>claude</a></li></ul></nav></div></article></main><footer><div style=display:flex><a class=soc href=https://github.com/xvnpw rel=me title=GitHub><i data-feather=github></i></a>
<a class=border></a><a class=soc href=https://twitter.com/xvnpw rel=me title=Twitter><i data-feather=twitter></i></a>
<a class=border></a><a class=soc href=https://www.linkedin.com/in/marcin-niemiec-304349104/ rel=me title=Linkedin><i data-feather=linkedin></i></a>
<a class=border></a></div><div class=footer-info>2024 <a href=https://github.com/athul/archie>Archie Theme</a> | Built with <a href=https://gohugo.io>Hugo</a></div></footer><script async src="https://www.googletagmanager.com/gtag/js?id=G-YHETMXZXMZ"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-YHETMXZXMZ")}</script><script>feather.replace()</script></div></body></html>